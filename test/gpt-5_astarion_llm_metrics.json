{
  "accuracy": 0.5410094637223974,
  "per_class": {
    "Highly disapprove": {
      "precision": 0.7241379310344828,
      "recall": 0.44680851063829785,
      "f1": 0.5526315789473685,
      "support": 141
    },
    "Disapprove": {
      "precision": 0.4807692307692308,
      "recall": 0.36496350364963503,
      "f1": 0.4149377593360996,
      "support": 137
    },
    "Approve": {
      "precision": 0.4127659574468085,
      "recall": 0.5574712643678161,
      "f1": 0.4743276283618582,
      "support": 174
    },
    "Highly approve": {
      "precision": 0.6394230769230769,
      "recall": 0.7307692307692307,
      "f1": 0.6820512820512821,
      "support": 182
    }
  },
  "classification_report": "                   precision    recall  f1-score   support\n\nHighly disapprove       0.72      0.45      0.55       141\n       Disapprove       0.48      0.36      0.41       137\n          Approve       0.41      0.56      0.47       174\n   Highly approve       0.64      0.73      0.68       182\n\n         accuracy                           0.54       634\n        macro avg       0.56      0.53      0.53       634\n     weighted avg       0.56      0.54      0.54       634\n",
  "binary": {
    "accuracy": 0.7839116719242902,
    "per_class": {
      "negative": {
        "precision": 0.8691099476439791,
        "recall": 0.5971223021582733,
        "f1": 0.7078891257995735,
        "support": 278
      },
      "positive": {
        "precision": 0.7471783295711061,
        "recall": 0.9297752808988764,
        "f1": 0.8285356695869838,
        "support": 356
      }
    },
    "classification_report": "              precision    recall  f1-score   support\n\n    negative       0.87      0.60      0.71       278\n    positive       0.75      0.93      0.83       356\n\n    accuracy                           0.78       634\n   macro avg       0.81      0.76      0.77       634\nweighted avg       0.80      0.78      0.78       634\n"
  }
}